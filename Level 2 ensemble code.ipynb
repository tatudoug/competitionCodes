{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/douglas/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.svm import LinearSVC\n",
    "from tffm import TFFMClassifier\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation,Input\n",
    "from keras.models import Sequential,Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "# data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n",
      "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
      "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
      "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
      "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
      "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
      "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
      "\n",
      "     var_7   ...     var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
      "0  18.6266   ...      4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
      "1  16.5338   ...      7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
      "2  14.6155   ...      2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
      "3  14.9250   ...      4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
      "4  19.2514   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
      "\n",
      "   var_196  var_197  var_198  var_199  \n",
      "0   7.8784   8.5635  12.7803  -1.0914  \n",
      "1   8.1267   8.7889  18.3560   1.9518  \n",
      "2  -6.5213   8.2675  14.7222   0.3965  \n",
      "3  -2.9275  10.2922  17.9697  -8.9996  \n",
      "4   3.9267   9.5031  17.9974  -8.8104  \n",
      "\n",
      "[5 rows x 202 columns]\n"
     ]
    }
   ],
   "source": [
    "#load or create your dataset\n",
    "print('Load data...')\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "print(df_train.head())\n",
    "df_test = pd.read_csv('test.csv')\n",
    "ID = df_test['ID_code']\n",
    "del df_test['ID_code']\n",
    "\n",
    "# delete duplicated based on time\n",
    "del df_train['ID_code']\n",
    "df_train.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "# y_train output - deleted target value\n",
    "y_train = df_train.target\n",
    "del df_train['target']\n",
    "\n",
    "# x_train\n",
    "X_train = df_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (False):\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fd5db63deef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;34m'objective'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#'binary',xentropy;xentlambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m'num_leaves'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# 31\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4.108467241113353\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m#0.01,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;34m'feature_fraction'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.02720614438477189\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#0.9,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;34m'bagging_fraction'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.8350603586533163\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#0.8,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "lgbmModels = []\n",
    "lgbmACC = []\n",
    "lgbmAUC = []\n",
    "\n",
    "params = {\n",
    "        'task': 'train',\n",
    "        #'boosting_type': 'gbdt',\n",
    "        'objective': 'xentropy',#'binary',xentropy;xentlambda\n",
    "        'num_leaves': int(30),      # 31\n",
    "        'learning_rate': np.exp(-4.108467241113353),   #0.01,\n",
    "        'feature_fraction': 0.02720614438477189,#0.9,\n",
    "        'bagging_fraction': 0.8350603586533163,#0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'max_depth': 6,        #-1,\n",
    "        'min_data_in_leaf': 13, #20,\n",
    "        'lambda_l2': 4,        # 0,\n",
    "        'is_unbalance' : False,\n",
    "        'max_bin' : int(75),\n",
    "        'verbose': -1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 39913\n",
      "n - iteration 0\n",
      "ROC :  0.8901408095289649\n",
      "ACC: 0.8140046498837529\n",
      "n - iteration 1\n",
      "ROC :  0.8916050566212322\n",
      "ACC: 0.8152546186345342\n",
      "n - iteration 2\n",
      "ROC :  0.890091495221151\n",
      "ACC: 0.8132546686332842\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8e4b5d2198ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#lgb_train = lgb.Dataset(X_train[train_index], y_train[train_index])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#gbm = lgb.train(params,lgb_train, num_boost_round=3688, verbose_eval= 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m#print('Ones', np.sum(y_pred > 0.5))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[1;32m   2159\u001b[0m         return predictor.predict(data, num_iteration,\n\u001b[1;32m   2160\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m                                  data_has_header, is_reshape)\n\u001b[0m\u001b[1;32m   2162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[0;34m(self, mat, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__pred_for_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[0;34m(mat, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_parameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_num_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                 preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_preds\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mout_num_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length for predict results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42) # all model have to use this \n",
    "np.random.seed(42)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train,y_train):\n",
    "    print('test',train_index[0])\n",
    "    for n in np.arange(20):      \n",
    "        limit = 10000 # number of 1s \n",
    "        \n",
    "        train_index = np.random.permutation(train_index)\n",
    "        part1 = train_index[y_train[train_index] ==1] # values with 1\n",
    "        part1 = np.random.permutation(part1)[0:limit]\n",
    "        # same number of values with 0\n",
    "              \n",
    "        \n",
    "        part2 = train_index[y_train[train_index] == 0]\n",
    "        \n",
    "        # building training data        \n",
    "        train_indexMod = np.r_[ part1, part2[0:limit] ]\n",
    "        \n",
    "        \n",
    "        lgb_train = lgb.Dataset(X_train[train_indexMod], y_train[train_indexMod]) \n",
    "        gbm = lgb.train(params,lgb_train, num_boost_round=4575, verbose_eval= 1)\n",
    "        \n",
    "        \n",
    "        #lgb_train = lgb.Dataset(X_train[train_index], y_train[train_index]) \n",
    "        #gbm = lgb.train(params,lgb_train, num_boost_round=3688, verbose_eval= 1)\n",
    "        y_pred = gbm.predict(X_train[test_index])\n",
    "        #print('Ones', np.sum(y_pred > 0.5))\n",
    "        \n",
    "        rocData = roc_auc_score(y_train[test_index],y_pred)\n",
    "        accData = accuracy_score(y_train[test_index],np.round(y_pred))\n",
    "        \n",
    "        print('n - iteration',n)\n",
    "        print('ROC : ', rocData )\n",
    "        print('ACC:', accData)\n",
    "        #print(classification_report(y_train[test_index], np.round(y_pred)))\n",
    "        lgbmACC.append(accData)\n",
    "        lgbmAUC.append(rocData)\n",
    "        lgbmModels.append(copy.deepcopy(gbm) )\n",
    "        #print('ROC rounded: ', roc_auc_score(y_train[test_index],np.round(y_pred)))\n",
    "        #print('ROC proba: ', roc_auc_score(y_train[test_index],gbm.predict_proba(X_train[test_index])))\n",
    "        #indices = (y_train[test_index] == 1)\n",
    "        #buff = y_train[test_index] \n",
    "        #print('ACCminorClass:', np.sum( np.round(y_pred[indices])==buff[indices] )/indices.shape )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting values\n",
    "print('ACC',np.mean(lgbmACC))\n",
    "print('AUC', np.mean(lgbmAUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving variables\n",
    "file = open('lgbmModel', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(lgbmModels, file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbmModels = []\n",
    "gbmACC = []\n",
    "gbmAUC = []\n",
    "\n",
    "params = {\n",
    "            'task': 'train',\n",
    "            'booster': 'gbtree',\n",
    "            'objective': 'binary:logistic',#'binary',\n",
    "            'num_leaves': int(30),      # 31\n",
    "            'learning_rate': np.exp(-4.108467241113353),   #0.01, Uses log values to improve optimization\n",
    "            'colsample_bytree': 0.02720614438477189,#0.9,\n",
    "            'subsample':  0.8350603586533163,#0.8,\n",
    "            'max_depth': 6,        #-1,\n",
    "            'min_child_weight': 10, #default=1,\n",
    "            'lambda':4,        # 0,\n",
    "            #'is_unbalance' : False,\n",
    "            'max_bin' : int(75),\n",
    "            #'nthread':3,\n",
    "            #'verbosity': 0    \n",
    "            'silent':1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42) # all model have to use this \n",
    "np.random.seed(42)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train,y_train):\n",
    "    print('test',train_index[0])\n",
    "    \n",
    "    if (train_index[0] == 0):\n",
    "        #saving variables\n",
    "        file = open('gbmModel', 'wb')\n",
    "        # dump information to that file\n",
    "        pickle.dump(gbmModels, file)\n",
    "        # close the file\n",
    "        file.close()\n",
    "    \n",
    "    for n in np.arange(20): \n",
    "        limit = 10000 # number of 1s \n",
    "        \n",
    "        train_index = np.random.permutation(train_index)\n",
    "        part1 = train_index[y_train[train_index] ==1] # values with 1\n",
    "        part1 = np.random.permutation(part1)[0:limit]\n",
    "        # same number of values with 0\n",
    "        part2 = train_index[y_train[train_index] == 0]\n",
    "        \n",
    "        # building training data        \n",
    "        train_indexMod = np.r_[ part1, part2[0:limit] ]        \n",
    "        \n",
    "        xgb_train = xgb.DMatrix(data = X_train[train_indexMod], label= y_train[train_indexMod]) \n",
    "        gbm = xgb.train(params,xgb_train, 4575)\n",
    "\n",
    "        y_pred = gbm.predict(xgb.DMatrix(data =X_train[test_index]))\n",
    "        \n",
    "        rocData = roc_auc_score(y_train[test_index],y_pred)\n",
    "        accData = accuracy_score(y_train[test_index],np.round(y_pred))\n",
    "        \n",
    "        print('n - iteration',n)\n",
    "        print('ROC : ', rocData )\n",
    "        print('ACC:', accData)\n",
    "        #print(classification_report(y_train[test_index], np.round(y_pred)))\n",
    "        gbmACC.append(accData)\n",
    "        gbmAUC.append(rocData)\n",
    "        gbmModels.append(copy.deepcopy(gbm) )\n",
    "        #print('ROC rounded: ', roc_auc_score(y_train[test_index],np.round(y_pred)))\n",
    "        #print('ROC proba: ', roc_auc_score(y_train[test_index],gbm.predict_proba(X_train[test_index])))\n",
    "        #indices = (y_train[test_index] == 1)\n",
    "        #buff = y_train[test_index] \n",
    "        #print('ACCminorClass:', np.sum( np.round(y_pred[indices])==buff[indices] )/indices.shape )\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting values\n",
    "print('ACC',np.mean(gbmACC))\n",
    "print('AUC', np.mean(gbmAUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving variables\n",
    "file = open('gbmModel', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(gbmModels, file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (True):\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    \n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmModels = []\n",
    "svmACC = []\n",
    "svmAUC = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42) # all model have to use this \n",
    "np.random.seed(42)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train,y_train):\n",
    "    print('test',train_index[0])\n",
    "    for n in np.arange(20): \n",
    "        limit = 10000 # number of 1s \n",
    "        train_index = np.random.permutation(train_index)\n",
    "        part1 = train_index[y_train[train_index] ==1] # values with 1\n",
    "        part1 = np.random.permutation(part1)[0:limit]\n",
    "        # same number of values with 0\n",
    "              \n",
    "        \n",
    "        part2 = train_index[y_train[train_index] == 0]\n",
    "        \n",
    "        # building training data        \n",
    "        train_indexMod = np.r_[ part1, part2[0:limit] ]\n",
    "    \n",
    "        model = LinearSVC( C =1 )\n",
    "        #clf = CalibratedClassifierCV(model) \n",
    "        model.fit(X_train[train_indexMod], y_train[train_indexMod])\n",
    "    \n",
    "        y_pred = model.predict(X_train[test_index])\n",
    "                \n",
    "        rocData = roc_auc_score(y_train[test_index],y_pred)\n",
    "        accData = accuracy_score(y_train[test_index],np.round(y_pred))\n",
    "        \n",
    "        print('n - iteration',n)\n",
    "        print('ROC : ', rocData )\n",
    "        print('ACC:', accData)\n",
    "        #print(classification_report(y_train[test_index], np.round(y_pred)))\n",
    "        svmACC.append(accData)\n",
    "        svmAUC.append(rocData)\n",
    "        svmModels.append(copy.deepcopy(model) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting values\n",
    "print('ACC',np.mean(svmACC))\n",
    "print('AUC', np.mean(svmAUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving variables\n",
    "file = open('svmModel', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(svmModels, file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmModels = []\n",
    "fmACC = []\n",
    "fmAUC = []        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42) # all model have to use this \n",
    "np.random.seed(42)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train,y_train):\n",
    "    print('test',train_index[0])\n",
    "    for n in np.arange(20): \n",
    "        limit = 10000 # number of 1s \n",
    "        train_index = np.random.permutation(train_index)\n",
    "        part1 = train_index[y_train[train_index] ==1] # values with 1\n",
    "        part1 = np.random.permutation(part1)[0:limit]\n",
    "        # same number of values with 0\n",
    "        \n",
    "        ### improve the way I save the models\n",
    "        model = TFFMClassifier(\n",
    "                order=3,\n",
    "                rank=10,\n",
    "                optimizer=tf.train.AdamOptimizer(learning_rate=0.0001), \n",
    "                n_epochs=50, \n",
    "                batch_size=1024,\n",
    "                init_std=0.01,\n",
    "                reg=10.0,\n",
    "                input_type='dense'\n",
    "                )\n",
    "        \n",
    "        part2 = train_index[y_train[train_index] == 0]\n",
    "        \n",
    "        # building training data        \n",
    "        train_indexMod = np.r_[ part1, part2[0:limit] ]\n",
    "        \n",
    "        model.fit(X_train, y_train, show_progress=False)\n",
    "        y_pred = model.predict_proba(X_train[test_index])[:,1]\n",
    "        \n",
    "        rocData = roc_auc_score(y_train[test_index],y_pred)\n",
    "        accData = accuracy_score(y_train[test_index],np.round(y_pred))\n",
    "        \n",
    "        print('n - iteration',n)\n",
    "        print('ROC : ', rocData )\n",
    "        print('ACC:', accData)\n",
    "        #print(classification_report(y_train[test_index], np.round(y_pred)))\n",
    "        fmACC.append(accData)\n",
    "        fmAUC.append(rocData)\n",
    "        fmModels.append(model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting values\n",
    "print('ACC',np.mean(fmACC))\n",
    "print('AUC', np.mean(fmAUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salva FM models\n",
    "val = 0\n",
    "for modelo in fmModels:\n",
    "    modelo.save_state('./fm/model'+ str(val) + '.tf')\n",
    "    val+=1\n",
    "#model.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = IsolationForest( max_samples=10000,\n",
    "                      random_state=42, contamination=0.1,n_estimators = 1000,max_features=0.1)\n",
    "isoModels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42) # all model have to use this \n",
    "np.random.seed(42)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train,y_train):\n",
    "    print(train_index[0])\n",
    "    clf.fit( X_train[train_index] )\n",
    "    isoModels.append(clf)\n",
    "#y_pred_train = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs',C = 0.1)\n",
    "logModels = []\n",
    "logACC = []\n",
    "logAUC = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42) # all model have to use this \n",
    "np.random.seed(42)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train,y_train):\n",
    "    print('test',train_index[0])\n",
    "    for n in np.arange(20): \n",
    "        limit = 10000 # number of 1s \n",
    "        train_index = np.random.permutation(train_index)\n",
    "        part1 = train_index[y_train[train_index] ==1] # values with 1\n",
    "        part1 = np.random.permutation(part1)[0:limit]\n",
    "        # same number of values with 0\n",
    "              \n",
    "        \n",
    "        part2 = train_index[y_train[train_index] == 0]\n",
    "        \n",
    "        # building training data        \n",
    "        train_indexMod = np.r_[ part1, part2[0:limit] ]\n",
    "    \n",
    "        clf.fit(X_train[train_indexMod], y_train[train_indexMod])\n",
    "        \n",
    "        y_pred = clf.predict_proba(X_train[test_index])[:,1]\n",
    "        \n",
    "        rocData = roc_auc_score(y_train[test_index],y_pred)\n",
    "        accData = accuracy_score(y_train[test_index],np.round(y_pred))\n",
    "        \n",
    "        print('n - iteration',n)\n",
    "        print('ROC : ', rocData )\n",
    "        print('ACC:', accData)\n",
    "        #print(classification_report(y_train[test_index], np.round(y_pred)))\n",
    "        logACC.append(accData)\n",
    "        logAUC.append(rocData)\n",
    "        logModels.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting values\n",
    "print('ACC',np.mean(logACC))\n",
    "print('AUC', np.mean(logAUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving variables\n",
    "file = open('logModel', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(logModels, file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier(n_estimators=1000, min_samples_split=2, random_state=0,n_jobs=4)\n",
    "extModels = []\n",
    "extACC = []\n",
    "extAUC = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42) # all model have to use this \n",
    "np.random.seed(42)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train,y_train):\n",
    "    print('test',train_index[0])\n",
    "    for n in np.arange(20): \n",
    "        limit = 1000 # number of 1s \n",
    "        train_index = np.random.permutation(train_index)\n",
    "        part1 = train_index[y_train[train_index] ==1] # values with 1\n",
    "        part1 = np.random.permutation(part1)[0:limit]\n",
    "        # same number of values with 0\n",
    "        part2 = train_index[y_train[train_index] == 0]\n",
    "        \n",
    "        # building training data        \n",
    "        train_indexMod = np.r_[ part1, part2[0:limit] ]\n",
    "        \n",
    "        model.fit(X_train[train_indexMod], y_train[train_indexMod])\n",
    "        \n",
    "        y_pred = model.predict_proba(X_train[test_index])[:,1]\n",
    "        \n",
    "        rocData = roc_auc_score(y_train[test_index],y_pred)\n",
    "        accData = accuracy_score(y_train[test_index],np.round(y_pred))\n",
    "        \n",
    "        print('n - iteration',n)\n",
    "        print('ROC : ', rocData )\n",
    "        print('ACC:', accData)\n",
    "        #print(classification_report(y_train[test_index], np.round(y_pred)))\n",
    "        #print(classification_report(y_train[test_index], np.round(y_pred)))\n",
    "        extACC.append(accData)\n",
    "        extAUC.append(rocData)\n",
    "        extModels.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=1000, random_state=0,bootstrap=0.7,n_jobs=4)\n",
    "rftModels = []\n",
    "rftACC = []\n",
    "rftAUC = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42) # all model have to use this \n",
    "np.random.seed(42)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train,y_train):\n",
    "    print('test',train_index[0])\n",
    "    for n in np.arange(20): \n",
    "        limit = 10000 # number of 1s \n",
    "        train_index = np.random.permutation(train_index)\n",
    "        part1 = train_index[y_train[train_index] ==1] # values with 1\n",
    "        part1 = np.random.permutation(part1)[0:limit]\n",
    "        # same number of values with 0\n",
    "        part2 = train_index[y_train[train_index] == 0]\n",
    "        \n",
    "        # building training data        \n",
    "        train_indexMod = np.r_[ part1, part2[0:limit] ]\n",
    "        \n",
    "        model.fit(X_train[train_indexMod], y_train[train_indexMod])\n",
    "        \n",
    "        y_pred = model.predict_proba(X_train[test_index])[:,1]\n",
    "        \n",
    "        rocData = roc_auc_score(y_train[test_index],y_pred)\n",
    "        accData = accuracy_score(y_train[test_index],np.round(y_pred))\n",
    "        \n",
    "        print('n - iteration',n)\n",
    "        print('ROC : ', rocData )\n",
    "        print('ACC:', accData)\n",
    "        #print(classification_report(y_train[test_index], np.round(y_pred)))\n",
    "\n",
    "        rftACC.append(accData)\n",
    "        rftAUC.append(rocData)\n",
    "        rftModels.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tsne_plot(x1, y1, name=\"graph.png\"):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    X_t = tsne.fit_transform(x1)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(X_t[np.where(y1 == 0), 0], X_t[np.where(y1 == 0), 1], marker='o', color='g', linewidth='1', alpha=0.8, label='Non Fraud')\n",
    "    plt.scatter(X_t[np.where(y1 == 1), 0], X_t[np.where(y1 == 1), 1], marker='o', color='r', linewidth='1', alpha=0.8, label='Fraud')\n",
    "\n",
    "    plt.legend(loc='best');\n",
    "    #plt.savefig(name);\n",
    "    plt.show();\n",
    "    \n",
    "tsne_plot(X_train[0:4000], y_train[0:4000], \"original.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(40, input_dim= X_train.shape[1],activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2, activation='linear'))\n",
    "model.add(Dense(5, activation='tanh'))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(X_train.shape[1], activation='linear'))\n",
    "        \n",
    "        \n",
    "model.compile(#loss=custom_objective,\n",
    "               loss = 'binary_crossentropy',\n",
    "               optimizer=keras.optimizers.SGD(lr=0.0001),\n",
    "               metrics=['MSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_scale = scaler.transform(X_train)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(X_scale) # X_train\n",
    "X_scale = scaler.transform(X_scale) # X_train\n",
    "'''\n",
    "# Standarize\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_scale = scaler.transform(X_train)\n",
    "'''\n",
    "#\n",
    "model.fit(X_scale[y_train == 1], X_scale[y_train == 1],\n",
    "                  batch_size=128,\n",
    "                  epochs=500,\n",
    "                  verbose=1,validation_split = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_representation = Sequential()\n",
    "hidden_representation.add(model.layers[0])\n",
    "hidden_representation.add(model.layers[1])\n",
    "hidden_representation.add(model.layers[2])\n",
    "hidden_representation.add(model.layers[3])\n",
    "hidden_representation.add(model.layers[4])\n",
    "hidden_representation.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm, x_fraud = X_scale[y == 0], X_scale[y == 1]\n",
    "\n",
    "norm_hid_rep = hidden_representation.predict(x_norm)\n",
    "fraud_hid_rep = hidden_representation.predict(x_fraud)\n",
    "y_n = np.zeros(norm_hid_rep.shape[0])\n",
    "y_f = np.ones(fraud_hid_rep.shape[0])\n",
    "rep_y = np.append(y_n, y_f)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(norm_hid_rep[:,0], norm_hid_rep[:,1], marker='o', color='g', linewidth='1', alpha=0.8, label='Non Fraud')\n",
    "plt.scatter(fraud_hid_rep[:,0],fraud_hid_rep[:,1], marker='o', color='r', linewidth='1', alpha=0.8, label='Fraud')\n",
    "\n",
    "plt.legend(loc='best');\n",
    "#plt.savefig(name);\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# level  2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lgbm load/predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file, where you stored the pickled data\n",
    "file = open('lgbmModel', 'rb')\n",
    "# dump information to that file\n",
    "l_lgbmModels = pickle.load(file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42) # all model have to use this \n",
    "np.random.seed(42)\n",
    "\n",
    "ind = 0\n",
    "vec = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train,y_train):\n",
    "    \n",
    "    acum = 0\n",
    "    for n in np.arange(20):\n",
    "        y_pred = l_lgbmModels[ind*20+n].predict(X_train[test_index])\n",
    "        acum += y_pred\n",
    "    \n",
    "    acum= acum/20 # get the mean value\n",
    "    \n",
    "    vec = np.r_[vec,acum]\n",
    "    ind = ind+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving variables\n",
    "file = open('lgbmPrevTest', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(vec, file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gbm load/predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving variables\n",
    "file = open('gbmModel', 'rb')\n",
    "# dump information to that file\n",
    "l_gbmModels = pickle.load(file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42) # all model have to use this \n",
    "np.random.seed(42)\n",
    "\n",
    "ind = 0\n",
    "vec = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train,y_train):\n",
    "    \n",
    "    acum = 0\n",
    "    for n in np.arange(20):\n",
    "        y_pred = l_gbmModels[ind*20+n].predict(xgb.DMatrix(data =X_train[test_index]))\n",
    "        acum += y_pred\n",
    "    \n",
    "    acum= acum/20 # get the mean value\n",
    "    \n",
    "    vec = np.r_[vec,acum]\n",
    "    ind = ind+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving variables\n",
    "file = open('gbmPrevTest', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(vec, file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svm load/predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving variables\n",
    "file = open('svmModel', 'rb')\n",
    "# dump information to that file\n",
    "l_svmModels = pickle.load(file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_trains = scaler.transform(X_train)\n",
    "    \n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(X_trains)\n",
    "X_train = scaler.transform(X_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42) # all model have to use this \n",
    "np.random.seed(42)\n",
    "\n",
    "ind = 0\n",
    "vec = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train,y_train):\n",
    "    \n",
    "    acum = 0\n",
    "    for n in np.arange(20):\n",
    "        y_pred = l_svmModels[ind*20+n].decision_function(X_trains[test_index])\n",
    "        acum += y_pred\n",
    "    \n",
    "    acum= acum/20 # get the mean value\n",
    "    \n",
    "    vec = np.r_[vec,acum]\n",
    "    ind = ind+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#saving variables\n",
    "file = open('svmPrevTest', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(vec, file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FM load/save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load fm model\n",
    "l_fmModels = []\n",
    "for n in np.arange(0,100):\n",
    "    model = TFFMClassifier(\n",
    "                    order=3,\n",
    "                    rank=10,\n",
    "                    optimizer=tf.train.AdamOptimizer(learning_rate=0.0001), \n",
    "                    n_epochs=50, \n",
    "                    batch_size=1024,\n",
    "                    init_std=0.01,\n",
    "                    reg=10.0,\n",
    "                    input_type='dense'\n",
    "                    )\n",
    "    model.core.set_num_features(X_train.shape[1])\n",
    "    model.load_state('./fm/model'+str(n)+'.tf')\n",
    "    l_fmModels.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42) # all model have to use this \n",
    "np.random.seed(42)\n",
    "\n",
    "ind = 0\n",
    "vec = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train,y_train):\n",
    "    \n",
    "    acum = 0\n",
    "    for n in np.arange(20):\n",
    "        y_pred = l_fmModels[ind*20+n].predict_proba(X_train[test_index])[:,1]\n",
    "        acum += y_pred\n",
    "    \n",
    "    acum= acum/20 # get the mean value\n",
    "    \n",
    "    vec = np.r_[vec,acum]\n",
    "    ind = ind+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving variables\n",
    "file = open('fmPrevTest', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(vec, file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log load/save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving variables\n",
    "file = open('logModel', 'rb')\n",
    "# dump information to that file\n",
    "l_logModels = pickle.load(file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42) # all model have to use this \n",
    "np.random.seed(42)\n",
    "\n",
    "ind = 0\n",
    "vec = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train,y_train):\n",
    "    \n",
    "    acum = 0\n",
    "    for n in np.arange(20):\n",
    "        y_pred = l_logModels[ind*20+n].predict_proba(X_train[test_index])[:,1]\n",
    "        acum += y_pred\n",
    "    \n",
    "    acum= acum/20 # get the mean value\n",
    "    \n",
    "    vec = np.r_[vec,acum]\n",
    "    ind = ind+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving variables\n",
    "file = open('logPrevTest', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(vec, file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('lgbmPrevTest', 'rb')\n",
    "yprev_lgbmPrev = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('gbmPrevTest', 'rb')\n",
    "yprev_gbmPrev = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('svmPrevTest', 'rb')\n",
    "yprev_svmPrev = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('fmPrevTest', 'rb')\n",
    "yprev_fmPrev = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('logPrevTest', 'rb')\n",
    "yprev_logPrev = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42) # all model have to use this \n",
    "np.random.seed(42)\n",
    "# Concatenates values\n",
    "y_prev = np.c_[yprev_lgbmPrev,yprev_gbmPrev,yprev_svmPrev,yprev_fmPrev,yprev_logPrev]\n",
    "\n",
    "y_teste = []\n",
    "for train_index, test_index in kf.split(X_train,y_train):\n",
    "    y_teste = np.r_[y_teste,y_train[test_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42) # all model have to use this \n",
    "np.random.seed(42)\n",
    "\n",
    "ind = 0\n",
    "vec = []\n",
    "\n",
    "for train_index, test_index in kf.split(y_prev,y_teste):\n",
    "    for n in np.arange(1):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(20, input_dim= y_prev.shape[1],activation='tanh'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(8, activation='tanh'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(2, activation='softmax'))\n",
    "        \n",
    "        \n",
    "        model.compile(#loss=custom_objective,\n",
    "                      loss = 'binary_crossentropy',#'binary_crossentropy',\n",
    "                      optimizer=keras.optimizers.SGD(lr=0.0001)\n",
    "                      )\n",
    "                      #metrics=['accuracy'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        epsilon = 0.1\n",
    "        y_train2 = copy.deepcopy(y_teste)\n",
    "        y_train2[y_train == 1] = 1-epsilon\n",
    "        y_train2[y_train == 0] = epsilon\n",
    "        \n",
    "        y_final = np.c_[y_train2, 1-y_train2]\n",
    "        \n",
    "        earlyStopping=keras.callbacks.EarlyStopping(monitor='roc_auc_score', patience=3, verbose=0, mode='auto')\n",
    "        \n",
    "        #model.fit(y_prev[train_indexMod], [y_train[train_indexMod],1-y_train[train_indexMod] ],\n",
    "        model.fit(y_prev[train_index], y_final[train_index],\n",
    "                  batch_size=128,\n",
    "                  epochs=50,\n",
    "                  callbacks=[earlyStopping], \n",
    "                  validation_split=0.2,\n",
    "                  verbose=1)\n",
    "        \n",
    "        y_fold = model.predict(y_prev[test_index])[:,0]\n",
    "        \n",
    "        rocData = roc_auc_score(y_train[test_index],y_fold)\n",
    "        accData = accuracy_score(y_train[test_index],np.round(y_fold))\n",
    "        \n",
    "        print('n - iteration',n)\n",
    "        print('ROC : ', rocData )\n",
    "        print('ACC:', accData)\n",
    "        print(classification_report(y_train[test_index], np.round(y_fold)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 200)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmModels100 = []\n",
    "lgbmACC100 = []\n",
    "lgbmAUC100 = []\n",
    "\n",
    "lgbmModels200 = []\n",
    "lgbmACC200 = []\n",
    "lgbmAUC200 = []\n",
    "\n",
    "params = {\n",
    "        'task': 'train',\n",
    "        #'boosting_type': 'gbdt',\n",
    "        'objective': 'xentropy',#'binary',xentropy;xentlambda\n",
    "        'num_leaves': int(30),      # 31\n",
    "        'learning_rate': np.exp(-4.108467241113353),   #0.01,\n",
    "        'feature_fraction': 0.02720614438477189,#0.9,\n",
    "        'bagging_fraction': 0.8350603586533163,#0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'max_depth': 6,        #-1,\n",
    "        'min_data_in_leaf': 13, #20,\n",
    "        'lambda_l2': 4,        # 0,\n",
    "        'is_unbalance' : True,\n",
    "        'max_bin' : int(75),\n",
    "        'verbose': -1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1\n",
      "ROC :  0.8121584830357537\n",
      "ACC: 0.10049748756281093\n",
      "Part 2\n",
      "ROC :  0.5173494759049864\n",
      "ACC: 0.10049748756281093\n",
      "Part 1\n",
      "ROC :  0.8116324314892008\n",
      "ACC: 0.10049748756281093\n",
      "Part 2\n",
      "ROC :  0.5209958932167211\n",
      "ACC: 0.10049748756281093\n",
      "Part 1\n",
      "ROC :  0.8132956603862289\n",
      "ACC: 0.1005\n",
      "Part 2\n",
      "ROC :  0.5033356840035509\n",
      "ACC: 0.1005\n",
      "Part 1\n",
      "ROC :  0.811990142432119\n",
      "ACC: 0.10047751193779844\n",
      "Part 2\n",
      "ROC :  0.5146125802383094\n",
      "ACC: 0.10047751193779844\n",
      "Part 1\n",
      "ROC :  0.8142798914715966\n",
      "ACC: 0.10047751193779844\n",
      "Part 2\n",
      "ROC :  0.5031979904790765\n",
      "ACC: 0.10047751193779844\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42) # all model have to use this \n",
    "np.random.seed(42)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train,y_train):\n",
    "        \n",
    "        print('Part 1')\n",
    "        #lgb_train = lgb.Dataset(X_train[train_index,0:100], y_train[train_index]) \n",
    "        lgb_train= lgb.Dataset(np.r_[X_train[train_index],df_test.values[kp,:]], np.r_[y_train[train_index],np.ones(len(kp))]) \n",
    "        gbm = lgb.train(params,lgb_train, num_boost_round=4575, verbose_eval= 1)\n",
    "        \n",
    "        y_pred = gbm.predict(X_train[test_index,0:100])\n",
    "        #print('Ones', np.sum(y_pred > 0.5))\n",
    "        \n",
    "        rocData = roc_auc_score(y_train[test_index],y_pred)\n",
    "        accData = accuracy_score(y_train[test_index],np.round(y_pred))\n",
    "        \n",
    "        #print('n - iteration',n)\n",
    "        print('ROC : ', rocData )\n",
    "        print('ACC:', accData)\n",
    "        #print(classification_report(y_train[test_index], np.round(y_pred)))\n",
    "        lgbmACC100.append(accData)\n",
    "        lgbmAUC100.append(rocData)\n",
    "        lgbmModels100.append(copy.deepcopy(gbm) )\n",
    "\n",
    "        print('Part 2')        \n",
    "        \n",
    "        #lgb_train = lgb.Dataset(X_train[train_index,100:], y_train[train_index]) \n",
    "        #lgb_train = lgb.Dataset(X_train[train_index], y_train[train_index]) \n",
    "        lgb_train= lgb.Dataset(np.r_[X_train[train_index],df_test.values[jp,:]], np.r_[y_train[train_index],np.ones(len(jp))]) \n",
    "        gbm = lgb.train(params,lgb_train, num_boost_round=4575, verbose_eval= 1)\n",
    "        y_pred = gbm.predict(X_train[test_index,100:])\n",
    "        #print('Ones', np.sum(y_pred > 0.5))\n",
    "        \n",
    "        rocData = roc_auc_score(y_train[test_index],y_pred)\n",
    "        accData = accuracy_score(y_train[test_index],np.round(y_pred))\n",
    "        \n",
    "        #print('n - iteration',n)\n",
    "        print('ROC : ', rocData )\n",
    "        print('ACC:', accData)\n",
    "        #print(classification_report(y_train[test_index], np.round(y_pred)))\n",
    "        lgbmACC200.append(accData)\n",
    "        lgbmAUC200.append(rocData)\n",
    "        lgbmModels200.append(copy.deepcopy(gbm) )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8994682949027432"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lgbmAUC200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "acum =[]\n",
    "for m in lgbmModels100:\n",
    "    \n",
    "    y_pred = m.predict(df_test.values[:,0:100])\n",
    "    \n",
    "    if len(acum):\n",
    "        acum = np.c_[acum,y_pred]\n",
    "    else:\n",
    "        acum = copy.deepcopy(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1751"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.sum(acum,axis=1)/5) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "acum2 =[]\n",
    "for m in lgbmModels200:\n",
    "    \n",
    "    y_pred = m.predict(df_test.values[:,100:])\n",
    "    \n",
    "    if len(acum2):\n",
    "        acum2 = np.c_[acum,y_pred]\n",
    "    else:\n",
    "        acum2 = copy.deepcopy(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2211"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((np.sum(acum2,axis=1)/5) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second round training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp = ((np.sum(acum,axis=1)/5) > 0.5)*np.arange(0,200000)\n",
    "kp = kp[kp>0]\n",
    "kn = ((np.sum(acum,axis=1)/5) < 0.05)*np.arange(0,200000)\n",
    "kn = kn[kn>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp = ((np.sum(acum2,axis=1)/5) > 0.5)*np.arange(0,200000)\n",
    "jp = jp[jp>0]\n",
    "jf = ((np.sum(acum2,axis=1)/5) < 0.05)*np.arange(0,200000)\n",
    "jf = jf[jf>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tee1 = np.intersect1d(jp,kp)\n",
    "tee2 = np.intersect1d(kn,jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1751,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm2Models100 = []\n",
    "lgbm2ACC100 = []\n",
    "lgbm2AUC100 = []\n",
    "\n",
    "lgbm2Models200 = []\n",
    "lgbm2ACC200 = []\n",
    "lgbm2AUC200 = []\n",
    "\n",
    "params = {\n",
    "        'task': 'train',\n",
    "        #'boosting_type': 'gbdt',\n",
    "        'objective': 'xentropy',#'binary',xentropy;xentlambda\n",
    "        'num_leaves': int(30),      # 31\n",
    "        'learning_rate': np.exp(-4.108467241113353),   #0.01,\n",
    "        'feature_fraction': 0.02720614438477189,#0.9,\n",
    "        'bagging_fraction': 0.8350603586533163,#0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'max_depth': 6,        #-1,\n",
    "        'min_data_in_leaf': 13, #20,\n",
    "        'lambda_l2': 4,        # 0,\n",
    "        'is_unbalance' : False,\n",
    "        'max_bin' : int(75),\n",
    "        'verbose': -1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1\n",
      "ROC :  0.8133114063378669\n",
      "ACC: 0.907027324316892\n",
      "Part 2\n",
      "ROC :  0.8161975758073533\n",
      "ACC: 0.9035774105647358\n",
      "Part 1\n",
      "ROC :  0.8137991222841353\n",
      "ACC: 0.907102322441939\n",
      "Part 2\n",
      "ROC :  0.8059949343081984\n",
      "ACC: 0.9030524236894077\n",
      "Part 1\n",
      "ROC :  0.8155865198742253\n",
      "ACC: 0.907825\n",
      "Part 2\n",
      "ROC :  0.818125727670707\n",
      "ACC: 0.903\n",
      "Part 1\n",
      "ROC :  0.8175853343090581\n",
      "ACC: 0.9064226605665142\n",
      "Part 2\n",
      "ROC :  0.814995281584237\n",
      "ACC: 0.9028725718142954\n",
      "Part 1\n",
      "ROC :  0.8177827774989312\n",
      "ACC: 0.9077976949423736\n",
      "Part 2\n",
      "ROC :  0.8203408047461053\n",
      "ACC: 0.9030725768144203\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42) # all model have to use this \n",
    "np.random.seed(42)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train,y_train):\n",
    "        \n",
    "        print('Part 1')\n",
    "        lgb_train = lgb.Dataset(np.r_[X_train[train_index,0:100],df_test.values[jp,0:100],df_test.values[jf,0:100]], np.r_[y_train[train_index],np.ones(len(jp)),np.zeros(len(jf))]) \n",
    "        #lgb_train = lgb.Dataset(np.r_[X_train[train_index,0:100],df_test.values[jp,0:100]], np.r_[y_train[train_index],np.ones(len(jp))])  \n",
    "        \n",
    "        gbm = lgb.train(params,lgb_train, num_boost_round=4575, verbose_eval= 1)\n",
    "        \n",
    "        y_pred = gbm.predict(X_train[test_index,0:100])\n",
    "        #print('Ones', np.sum(y_pred > 0.5))\n",
    "        \n",
    "        rocData = roc_auc_score(y_train[test_index],y_pred)\n",
    "        accData = accuracy_score(y_train[test_index],np.round(y_pred))\n",
    "        \n",
    "        #print('n - iteration',n)\n",
    "        print('ROC : ', rocData )\n",
    "        print('ACC:', accData)\n",
    "        #print(classification_report(y_train[test_index], np.round(y_pred)))\n",
    "        lgbm2ACC100.append(accData)\n",
    "        lgbm2AUC100.append(rocData)\n",
    "        lgbm2Models100.append(copy.deepcopy(gbm) )\n",
    "\n",
    "        print('Part 2')        \n",
    "        \n",
    "        lgb_train = lgb.Dataset(np.r_[X_train[train_index,100:],df_test.values[kp,100:],df_test.values[kn,100:]], np.r_[y_train[train_index],np.ones(len(kp)),np.zeros(len(kn))]) \n",
    "        #lgb_train = lgb.Dataset(np.r_[X_train[train_index,100:],df_test.values[kp,100:]], np.r_[y_train[train_index],np.ones(len(kp))]) \n",
    "        gbm = lgb.train(params,lgb_train, num_boost_round=4575, verbose_eval= 1)\n",
    "        y_pred = gbm.predict(X_train[test_index,100:])\n",
    "        #print('Ones', np.sum(y_pred > 0.5))\n",
    "        \n",
    "        rocData = roc_auc_score(y_train[test_index],y_pred)\n",
    "        accData = accuracy_score(y_train[test_index],np.round(y_pred))\n",
    "        \n",
    "        #print('n - iteration',n)\n",
    "        print('ROC : ', rocData )\n",
    "        print('ACC:', accData)\n",
    "        #print(classification_report(y_train[test_index], np.round(y_pred)))\n",
    "        lgbm2ACC200.append(accData)\n",
    "        lgbm2AUC200.append(rocData)\n",
    "        lgbm2Models200.append(copy.deepcopy(gbm) )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815235050567173 0.8151308648233202\n",
      "0.811700174446727 0.8152294277736806\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(lgbmAUC200),np.mean(lgbm2AUC200))\n",
    "print(np.mean(lgbmAUC100),np.mean(lgbm2AUC100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815235050567173 0.8152785819532303\n",
      "0.811700174446727 0.8151057485335447\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(lgbmAUC200),np.mean(lgbm2AUC200))\n",
    "print(np.mean(lgbmAUC100),np.mean(lgbm2AUC100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_train, yprev_lgbmPrev, n_bins=10)\n",
    "ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",label=\"%s\" % ('lgbm', ))\n",
    "\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_train, yprev_fmPrev, n_bins=10)\n",
    "ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",label=\"%s\" % ('fm', ))\n",
    "\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_train, yprev_gbmPrev, n_bins=10)\n",
    "ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",label=\"%s\" % ('gbm', ))\n",
    "\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_train, yprev_logPrev, n_bins=10)\n",
    "ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",label=\"%s\" % ('log', ))\n",
    "ax1.legend(loc=\"lower right\")\n",
    "\n",
    "ax1.set_ylabel(\"Fraction of positives\")\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.set_title('Calibration plots  (reliability curve)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in np.arange(0,5):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_train, y_prev[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "#fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_train.ravel(), y_prev.ravel())\n",
    "#roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yprev_lgbmPrev,yprev_gbmPrev,yprev_svmPrev,yprev_fmPrev,yprev_logPrev\n",
    "plt.figure()\n",
    "lw = 2\n",
    "\n",
    "plt.plot(fpr[0], tpr[0], color='black',\n",
    "         lw=lw, label='ROC curve GBM (area = %0.2f)' % roc_auc[0])\n",
    "\n",
    "plt.plot(fpr[1], tpr[1], color='green',\n",
    "         lw=lw, label='ROC curve LGBM (area = %0.2f)' % roc_auc[1])\n",
    "\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve svm (area = %0.2f)' % roc_auc[2])\n",
    "\n",
    "plt.plot(fpr[3], tpr[3], color='red',\n",
    "         lw=lw, label='ROC curve fm (area = %0.2f)' % roc_auc[3])\n",
    "\n",
    "plt.plot(fpr[4], tpr[4], color='gray',\n",
    "         lw=lw, label='ROC curve log (area = %0.2f)' % roc_auc[4])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train\n",
    "X_test = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('lgbmModel', 'rb')\n",
    "# dump information to that file\n",
    "l_lgbmModels = pickle.load(file)\n",
    "# close the file\n",
    "file.close()\n",
    "\n",
    "acum =0\n",
    "for n in np.arange(100):\n",
    "    y_pred = l_lgbmModels[n].predict(X_test)\n",
    "    acum += y_pred\n",
    "    \n",
    "acum= acum/100 # get the mean value\n",
    "\n",
    "#saving variables\n",
    "file = open('lgbmPrevFinal', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(acum, file)\n",
    "# close the file\n",
    "file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving variables\n",
    "file = open('gbmModel', 'rb')\n",
    "# dump information to that file\n",
    "l_gbmModels = pickle.load(file)\n",
    "# close the file\n",
    "file.close()\n",
    "\n",
    "acum =0\n",
    "for n in np.arange(100):\n",
    "    y_pred = l_gbmModels[n].predict(xgb.DMatrix(data =X_test))\n",
    "    acum += y_pred\n",
    "    \n",
    "acum= acum/100 # get the mean value\n",
    "\n",
    "#saving variables\n",
    "file = open('gbmPrevFinal', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(acum, file)\n",
    "# close the file\n",
    "file.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving variables\n",
    "file = open('svmModel', 'rb')\n",
    "# dump information to that file\n",
    "l_svmModels = pickle.load(file)\n",
    "# close the file\n",
    "file.close()\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_trains = scaler.transform(X_train)\n",
    "X_tests = scaler.transform(X_test)\n",
    "    \n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(X_trains)\n",
    "X_tests = scaler.transform(X_tests)\n",
    "\n",
    "acum =0\n",
    "for n in np.arange(100):\n",
    "    y_pred = l_svmModels[n].decision_function(X_tests)\n",
    "    acum += y_pred\n",
    "    \n",
    "acum= acum/100 # get the mean value\n",
    "\n",
    "#saving variables\n",
    "file = open('svmPrevFinal', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(acum, file)\n",
    "# close the file\n",
    "file.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load fm model\n",
    "'''    \n",
    "l_fmModels = []\n",
    "for n in np.arange(0,100):\n",
    "    model = TFFMClassifier(\n",
    "                    order=3,\n",
    "                    rank=10,\n",
    "                    optimizer=tf.train.AdamOptimizer(learning_rate=0.0001), \n",
    "                    n_epochs=50, \n",
    "                    batch_size=1024,\n",
    "                    init_std=0.01,\n",
    "                    reg=10.0,\n",
    "                    input_type='dense'\n",
    "                    )\n",
    "    model.core.set_num_features(X_train.shape[1])\n",
    "    model.load_state('./fm/model'+str(n)+'.tf')\n",
    "    l_fmModels.append(model)\n",
    "\n",
    "'''\n",
    "acum =[]\n",
    "for n in np.arange(100):   \n",
    "    y_pred = l_fmModels[n].predict_proba(X_test)[:,1]\n",
    "    if len(acum):\n",
    "        acum = np.c_[acum,y_pred]\n",
    "    else:\n",
    "        acum = copy.deepcopy(y_pred)\n",
    "'''    \n",
    "acum= acum/100 # get the mean value\n",
    "\n",
    "#saving variables\n",
    "file = open('fmPrevFinal', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(acum, file)\n",
    "# close the file\n",
    "file.close()  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acum1 = np.mean(acum,axis=1)\n",
    "acum2 = np.median(acum,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(yprev_fmPrev>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm1 = np.mean(acum[:,0:20],axis=1)\n",
    "fm2 = np.mean(acum[:,20:40],axis=1)\n",
    "fm3 = np.mean(acum[:,40:60],axis=1)\n",
    "fm4 = np.mean(acum[:,60:80],axis=1)\n",
    "fm5 = np.mean(acum[:,80:100],axis=1)\n",
    "end = np.c_[fm1,fm2,fm3,fm4,fm5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(end>0.5,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('lgbmPrevFinal', 'rb')\n",
    "lgbmPrevFinal = pickle.load(file)\n",
    "file.close()\n",
    "file = open('gbmPrevFinal', 'rb')\n",
    "gbmPrevFinal = pickle.load(file)\n",
    "file.close()\n",
    "file = open('svmPrevFinal', 'rb')\n",
    "svmPrevFinal = pickle.load(file)\n",
    "file.close()\n",
    "file = open('fmPrevFinal', 'rb')\n",
    "fmPrevFinal = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmPrevFinal2 = svmPrevFinal-(min(svmPrevFinal))\n",
    "svmPrevFinal2 = svmPrevFinal2/max(svmPrevFinal2)\n",
    "\n",
    "y_prev = np.c_[lgbmPrevFinal,gbmPrevFinal,svmPrevFinal2,fmPrevFinal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = np.array([0.12659275, 0.21944339, 0.35109897, 0.30286489])\n",
    "geometric = (y_prev*mat1)\n",
    "geometric = geometric[:,0]*geometric[:,1]*geometric[:,2]*geometric[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat2 = np.array([0.44948398, 0.13951325, 0.07288259, 0.33812018])\n",
    "meanV = (y_prev*mat2)\n",
    "meanV = np.sum(meanV,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanV = np.sqrt(lgbmPrevFinal*gbmPrevFinal)\n",
    "meanV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([ID, pd.DataFrame(meanV)],axis=1)#,columns=['session_id', 'is_click'])\n",
    "submission.columns = ['ID_code', 'target']\n",
    "submission.to_csv('beforeIgo.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanV = (lgbmPrevFinal+gbmPrevFinal)/2\n",
    "meanV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([ID, pd.DataFrame(meanV)],axis=1)#,columns=['session_id', 'is_click'])\n",
    "submission.columns = ['ID_code', 'target']\n",
    "submission.to_csv('mean2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(meanV > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2 = np.power(lgbmPrevFinal*gbmPrevFinal*fmPrevFinal,1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(sub2>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([ID, pd.DataFrame(sub2)],axis=1)#,columns=['session_id', 'is_click'])\n",
    "submission.columns = ['ID_code', 'target']\n",
    "submission.to_csv('sumData2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Crazy codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(y_prev[:,2])\n",
    "k = y_prev[:,2]\n",
    "\n",
    "k =  k - min(k)\n",
    "k = k / max(k)\n",
    "y_prev[:,2] = 1-k\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = np.mean(y_prev,axis = 1)            \n",
    "\n",
    "submission = pd.concat([ID, pd.DataFrame(final)],axis=1)#,columns=['session_id', 'is_click'])\n",
    "submission.columns = ['ID_code', 'target']\n",
    "submission.to_csv('meanVal.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardCode = np.round(y_prev[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(hardCode[:,1:],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = np.mean(y_prev[:,0:2],axis = 1) \n",
    "#yprev_lgbmPrev,yprev_gbmPrev,yprev_svmPrev,yprev_fmPrev,yprev_logPrev\n",
    "rocData = roc_auc_score(y_teste,final)\n",
    "rocData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jjj = []\n",
    "jkk = []\n",
    "for x in np.arange(0,10000):\n",
    "    i = np.array([random.random(),random.random(),random.random(),random.random(),random.random()])\n",
    "    i = i/np.sum(i)\n",
    "    # np.power(values, 1/3)\n",
    "    y_prevj = y_prev*i\n",
    "    rocData = roc_auc_score(y_teste,np.power(y_prevj[:,0]*y_prevj[:,1]*y_prevj[:,2]*y_prevj[:,3]*y_prevj[:,4],5))\n",
    "    jj.append(rocData)\n",
    "    jk.append(i)\n",
    "    \n",
    "    \n",
    "    rocData = roc_auc_score(y_teste,np.mean(y_prevj,axis=1))\n",
    "    jjj.append(rocData)\n",
    "    jkk.append(i)\n",
    "    #print(i)\n",
    "    #print(rocData)\n",
    "print(max(jj))\n",
    "print(jk[np.argmax(jj)])\n",
    "print('2')\n",
    "print(max(jjj))\n",
    "print(jkk[np.argmax(jjj)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(jj))\n",
    "print(jk[np.argmax(jj)])\n",
    "print('2')\n",
    "print(max(jjj))\n",
    "print(jkk[np.argmax(jjj)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "    np.array[random.random(),random.random(),random.random(),random.random(),random.random()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prev*i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jk[np.argmax(jj)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([0.39823669, 0.14117335, 0.09870075, 0.34496129, 0.01692792]) # 0.9035755088777733"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.power(values, 1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.9014410654261418\n",
    "[0.12659275 0.21944339 0.33370293 0.30286489 0.01739604]\n",
    "2\n",
    "0.9041437196865552\n",
    "[0.44436681 0.13951325 0.07288259 0.33812018 0.00511717]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('svmPrevTest', 'rb')\n",
    "yprev_svmPrev = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(yprev_svmPrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(yprev_svmPrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = (y_train==1)\n",
    "a = (np.round(yprev_lgbmPrev[indexes]) == 1)\n",
    "\n",
    "b = (np.round(yprev_gbmPrev[indexes]) == 1)\n",
    "\n",
    "k = (np.sign(yprev_svmPrev))\n",
    "k[k<-0.5] = 0\n",
    "k\n",
    "c = (np.round(k[indexes]) == 1)\n",
    "\n",
    "d = (np.round(yprev_fmPrev[indexes]) == 1)\n",
    "\n",
    "e = (np.round(yprev_logPrev[indexes])  == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a= 0\n",
    "p = (a.astype(int)+b.astype(int)+c.astype(int)+d.astype(int)+e.astype(int))\n",
    "p = (b.astype(int)+c.astype(int)+d.astype(int)+e.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(p == 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(a != (p==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.round(yprev_lgbmPrev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p >3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = (np.sign(yprev_svmPrev))\n",
    "k[k<-0.5] = 0\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
